# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

###################
# Common properties
###################

# HDFS root path. Should match 'fs.defaultFS' property in Hadoop's core-site.xml
test.common.hdfs.root=hdfs://localhost:8020
# YARN resource manager hostname. Should match 'yarn.resourcemanager.hostname' property in Hadoop's yarn-site.xml
test.common.yarn.resource.manager=localhost
# Memory (in MB) given to each container (if running in YARN)
test.common.yarn.container.memory.mb=1024
# Number of cores given to each container (if running in YARN)
test.common.yarn.container.cores=1

###################################
# Continuous ingest test properties
###################################

# Common
# ------
# Accumulo table used by continuous tests
test.ci.common.accumulo.table=ci
# Number of tablets that should exist in Accumulo table when created
test.ci.common.accumulo.num.tablets=20
# Optional authorizations that if specified will be randomly selected by scanners and walkers
# Format: a,b|a,b,c|c
test.ci.common.auths=
# Accumulo table properties to set when creating table
test.ci.common.accumulo.table.props=\
table.majc.compaction.strategy=org.apache.accumulo.tserver.compaction.strategies.BasicCompactionStrategy \
table.majc.compaction.strategy.opts.filter.size=250M \
table.majc.compaction.strategy.opts.large.compress.threshold=100M \
table.majc.compaction.strategy.opts.large.compress.type=gz

# Ingest
# ------
# Number of entries each ingest client should write
test.ci.ingest.client.entries=9223372036854775807
# Flush batch writer after this many entries.
test.ci.ingest.entries.flush=1000000
# Minimum random row to generate
test.ci.ingest.row.min=0
# Maximum random row to generate
test.ci.ingest.row.max=9223372036854775807
# Maximum number of random column families to generate
test.ci.ingest.max.cf=32767
# Maximum number of random column qualifiers to generate
test.ci.ingest.max.cq=32767
# Optional visibilities (in CSV format) that if specified will be randomly selected by ingesters for
# each linked list
test.ci.ingest.visibilities=
# Checksums will be generated during ingest if set to true
test.ci.ingest.checksum=true
# Enables periodic pausing of ingest. Pause checks are only done after a flush. To write small
# amounts of data and then pause, set pause.wait.max and entries.flush small.
test.ci.ingest.pause.enabled=false
# Minimum wait between ingest pauses (in seconds)
test.ci.ingest.pause.wait.min=120
# Maximum wait between ingest pauses (in seconds)
test.ci.ingest.pause.wait.max=180
# Minimum pause duration (in seconds)
test.ci.ingest.pause.duration.min=60
# Maximum pause duration (in seconds)
test.ci.ingest.pause.duration.max=120

# Batch walker
# ------------
# Sleep time between batch scans (in ms)
test.ci.batch.walker.sleep.ms=10000
# Scan batch size
test.ci.batch.walker.batch.size=10000

# Walker
# ------
# Sleep time between scans (in ms)
test.ci.walker.sleep.ms=10000

# Scanner
# -------
# Sleep time between scans (in ms)
test.ci.scanner.sleep.ms=10000
# Scanner entries
test.ci.scanner.entries=5000

# Verify
# -----
# Maximum number of mapreduce mappers
test.ci.verify.max.maps=4096
# Number of mapreduce reducers
test.ci.verify.reducers=64
# Perform the verification directly on the files while the table is offline
test.ci.verify.scan.offline=false
# Comma separated list of auths to use for verify
test.ci.verify.auths=
# Location in HDFS to store output. Must not exist.
test.ci.verify.output.dir=/tmp/ci-verify

# Bulk Ingest
# -----------
# The number of map task to run.
test.ci.bulk.map.task=10
# The number of nodes to generate per map task.
test.ci.bulk.map.nodes=1000000
# The number of reducers will be the minimum of this prop and table splits+1.  Each reducer will
# produce a bulk import file.
test.ci.bulk.reducers.max=1024

###############################
# Garbage Collection Simulation
###############################

# Name of Accumulo table to use for test
test.gcs.table=gcs
# Max number of buckets for references.  Buckets correspond to tablets in the Accumulo GC.
test.gcs.maxBuckets=100000
# Split each data section with this many tablets when creating table.
test.gcs.tablets=10
# Total number of work list the generator should create before it exits.
test.gcs.maxWork=100000000
# Max number of work list a generator should be concurrently working on.
test.gcs.maxActiveWork=10000
# Number of entries collector and verifier will read into memory.
test.gcs.batchSize=100000

#################
# MapReduce Tests
#################

# RowHash test
# ------------
# Table containing input data
test.rowhash.input.table = terasort
# Table where data will be output to
test.rowhash.output.table = rowhash
# Column that is fetched in input table
test.rowhash.column = c

# TeraSort ingest
# ---------------
# Table to ingest into
test.terasort.table = terasort
# Number of rows to ingest
test.terasort.num.rows = 10000
# Minimum key size
test.terasort.min.keysize = 10
# Maximum key size
test.terasort.max.keysize = 10
# Minimum value size
test.terasort.min.valuesize = 78
# Maximum value size
test.terasort.max.valuesize = 78
# Number of table splits
test.terasort.num.splits = 4
